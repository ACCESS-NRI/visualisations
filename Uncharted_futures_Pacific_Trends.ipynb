{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f531d0d-b557-4bfc-ac74-12f61e096109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import accessvis\n",
    "import glob\n",
    "import iris\n",
    "from esmvalcore.preprocessor import regrid\n",
    "from ncdata.iris_xarray import cubes_from_xarray\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import xarray as xr\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import dask.bag as dasb\n",
    "from dask.diagnostics import ProgressBar\n",
    "from scipy import signal\n",
    "from scipy.stats import spearmanr, norm\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import xskillscore as xskill\n",
    "import cmocean\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/548/cxc548/lib/python/bom-climate-change-variability-and-extreme-toolbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37b8a6-85a5-440a-8089-73ef5a825b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5f1c8-65fe-442f-b7b2-6704d4f0043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed as dask\n",
    "\n",
    "# client = dask.Client(threads_per_worker=1,n_workers=4, memory_limit='64GB')\n",
    "client = dask.Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495bef0-bc79-4ee8-87a5-0fa38aa99d44",
   "metadata": {},
   "source": [
    "# Method definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5cf189-02c3-4dcc-80ef-fa8cf83f287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trend(xarr, start,end,length):\n",
    "    #loop over years\n",
    "    for i in np.arange(start,end,1):\n",
    "        startyear=i\n",
    "        endyear=i+length\n",
    "        #extract window\n",
    "        arr = xarr.sel(year=slice(str(startyear),str(endyear)))\n",
    "    \n",
    "        timedim=np.arange(0,len(arr.year))\n",
    "        arr['year'] = timedim\n",
    "        #call polyfit to calculate trend over the window. multiply by 10 so we get units of trend per decade\n",
    "        trnd = ((arr.polyfit(dim='year',deg=1,skipna=True)).polyfit_coefficients.isel(degree=0))*10\n",
    " \n",
    "        #if it's the first year, copy the trend to trnarr\n",
    "        if i == start:\n",
    "            trnarr = trnd\n",
    "        #if it's the subsequent years, concatenate the trend to trnarr\n",
    "        else:\n",
    "            trnarr = xr.concat([trnarr,trnd],dim='year')\n",
    "\n",
    "    trnarr['year'] = np.arange(start,end,1)\n",
    "\n",
    "    return trnarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a49182-29ca-4698-b53f-b4d8b918bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_dataset(data):\n",
    "    cube_data=cubes_from_xarray(data)[0]\n",
    "    cube_regrided = regrid(cube_data, target_grid=\"1x1\", scheme=\"linear\")\n",
    "    return xr.DataArray.from_iris(cube_regrided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9caab77-374c-42e2-a5e3-aefc344526aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rgba(data, lon, lat, vmax=0.2, vmin=-0.2, Alpha=0.65):\n",
    "    \n",
    "    lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "    \n",
    "    cmap = cmocean.cm.balance\n",
    "    \n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 10), dpi=100)\n",
    "    cf = ax.contourf(lon2d, lat2d, data, cmap=cmap, norm=norm, levels=30)\n",
    "    ax.axis('off')\n",
    "    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    rgba = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
    "    rgba = rgba.reshape(fig.canvas.get_width_height()[::-1] + (4,))  # (H, W, 4)\n",
    "\n",
    "    rgba = rgba[:, :, [1, 2, 3, 0]]\n",
    "\n",
    "    # mask land\n",
    "    img = rgba.astype(float) / 255.0\n",
    "    tol = 0.99\n",
    "    mask_white = (img[..., :3] > tol).all(axis=-1)\n",
    "    rgba[mask_white, 3] = rgba[mask_white, 3] * 0.001  \n",
    "\n",
    "    rgba[:,:,3] = rgba[:,:,3]*Alpha\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return rgba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb3adf-bd5b-40fe-ac14-0e38b6919dc6",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e7b1dd-49bc-4f7e-86ea-f26ba1e4d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pattern=\"/g/data/fs38/publications/CMIP6/CMIP/CSIRO/ACCESS-ESM1-5/historical/r1i1p1f1/Omon/tos/gn/latest/*\"\n",
    "obs_pattern=\"/g/data/ct11/access-nri/replicas/esmvaltool/obsdata-v2/Tier2/NOAA-ERSSTv5/*\"\n",
    "\n",
    "ds_model=xr.open_mfdataset(model_pattern)\n",
    "ds_obs=xr.open_mfdataset(obs_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5ac09-9be3-48b9-bb31-30c2d5dab279",
   "metadata": {},
   "source": [
    "# Data pre-processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a20f45-8e11-485d-83ab-db0606db79fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.09/lib/python3.11/site-packages/iris/fileformats/cf.py:880: IrisCfMissingVarWarning: Missing CF-netCDF measure variable 'areacello', referenced by netCDF variable 'tos'\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.09/lib/python3.11/site-packages/iris/fileformats/cf.py:1475: IrisCfNonSpanningVarWarning: Ignoring variable lat_bnds referenced by variable lat: Dimensions ('time', 'lat', 'bnds') do not span ('lat',)\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.09/lib/python3.11/site-packages/iris/fileformats/cf.py:1475: IrisCfNonSpanningVarWarning: Ignoring variable lon_bnds referenced by variable lon: Dimensions ('time', 'lon', 'bnds') do not span ('lon',)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Regrid data\n",
    "\n",
    "regrided_model=regrid_dataset(ds_model)\n",
    "regrided_obs=regrid_dataset(ds_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045045f4-9418-4d63-b82e-36bfa5dee4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annual_mean\n",
    "\n",
    "ds_model_ann=regrided_model.groupby('time.year').mean('time')\n",
    "ds_obs_ann=regrided_obs.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64797fc7-4ef5-4ec8-8176-8ad66d5d7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 31 years trends\n",
    "\n",
    "ds_model_ann_trend_30 = calc_trend(ds_model_ann,1850,1980,31)\n",
    "ds_obs_ann_trend_30 = calc_trend(ds_obs_ann,1850,1980,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c2b3afa-0ff2-4050-bb9d-50bc0c4c47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rolling(annually) SSTA\n",
    "ds_obs = ds_obs.unify_chunks()\n",
    "ds_obs_anoms = ds_obs.groupby('time.month') - ds_obs.sel(time=slice('1850','1900')).groupby('time.month').mean('time')\n",
    "ds_obs_anoms_rolling = ds_obs_anoms.rolling(time=12, center=True).mean()\n",
    "\n",
    "# ds_model = ds_model.unify_chunks()\n",
    "# ds_model_anoms = ds_model.groupby('time.month') - ds_model.sel(time=slice('1850','1900')).groupby('time.month').mean('time')\n",
    "# ds_model_anoms_rolling = ds_model_anoms.rolling(time=12, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e904b3cb-5d8b-44ee-bee4-cacd96966434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To make video looks more smooth, we do some interpolation in trands data\n",
    "\n",
    "year = ds_obs_ann_trend_30[\"year\"].values\n",
    "new_year = np.linspace(year.min(), year.max(), len(year) * 4)\n",
    "ds_load=ds_obs_ann_trend_30.load()\n",
    "ds_interp_obs = (\n",
    "    ds_load\n",
    "    .chunk({'year': -1})       \n",
    "    .interp(year=new_year)    \n",
    "    .chunk({'year': 10, 'lat': 180, 'lon': 360})  \n",
    ")\n",
    "\n",
    "year = ds_model_ann_trend_30[\"year\"].values\n",
    "new_year = np.linspace(year.min(), year.max(), len(year) * 4)\n",
    "ds_load_model=ds_model_ann_trend_30.load()\n",
    "ds_interp_model = (\n",
    "    ds_load_model\n",
    "    .chunk({'year': -1})             \n",
    "    .interp(year=new_year)          \n",
    "    .chunk({'year': 10, 'lat': 180, 'lon': 360})  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099f4e3-9c87-43e8-afe7-202d9caa9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some specific camera spots which going to use in the video\n",
    "\n",
    "cam_aust={\n",
    "    # 'translate': [0.0, 0.0, -22.071718],\n",
    "    'translate': [0.0, 0.0, -14.071718],\n",
    "    'rotate': [0.003478, -0.91839, 0.218037, 0.330141],\n",
    "    'xyzrotate': [-149.899796, -37.438725, 170.021637],\n",
    "    'fov': 45.0,\n",
    "    'focus': [-0.014273, -0.037801, 0.001495]\n",
    "}\n",
    "\n",
    "cam_westpacific={\n",
    " 'translate': [0.0, 0.0, -26.93169],\n",
    " 'rotate': [0.00821, -0.998777, 0.000118, 0.048616],\n",
    " 'xyzrotate': [179.96759, -5.573063, -179.056473],\n",
    " 'fov': 45.0,\n",
    " 'focus': [-0.014273, -0.037801, 0.001495]\n",
    "}\n",
    "\n",
    "cam_eastpacific={\n",
    " 'translate': [0.0, 0.0, -26.93169],\n",
    " 'rotate': [0.001449, -0.855247, 0.001781, -0.518191],\n",
    " 'xyzrotate': [-179.437088, 62.419106, -179.464828],\n",
    " 'fov': 45.0,\n",
    " 'focus': [-0.014273, -0.037801, 0.001495]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc84296-167a-4a8e-8bf2-0064adf0758a",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd7f52-1ed1-43e6-8371-a330ac08d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/g/data/tm70/yz9299/ARE/video\"\n",
    "lv = accessvis.plot_earth(texture='bluemarble', background=\"white\", vertical_exaggeration=20)\n",
    "data_rolling=ds_anoms_rolling.isel(time=slice(6, -6))\n",
    "data_trend=ds_obs_ann_trend_30\n",
    "data_interp=ds_interp_obs\n",
    "\n",
    "\n",
    "with lv.video(filename=os.path.join(path,'SSTA_test_part1_1.mp4'), quality=2, resolution=(600,600), width=600, height=600, fps=30) as v:\n",
    "\n",
    "    # define parameters for video generation\n",
    "    Y=0\n",
    "    fps=v.\n",
    "    FIRST_PART=3\n",
    "    SECOND_PART=45\n",
    "    THIRD_PART=20\n",
    "    ALPHA=0.65\n",
    "    ALPHA_TIME=1.5\n",
    "\n",
    "    # define time for each part of the video\n",
    "    time_list=[]\n",
    "    \n",
    "    time_fristpart=fps*FIRST_PART\n",
    "    time_list.append(time_fristpart)\n",
    "    \n",
    "    time_secondpart=fps*SECOND_PART\n",
    "    time_list.append(time_secondpart)\n",
    "\n",
    "    time_thirdpart=fps*THIRD_PART\n",
    "    time_list.append(time_thirdpart)\n",
    "\n",
    "    time_total=sum(time_list)\n",
    "\n",
    "    # Part one: start with spinning globe and annual SSTAs from 1850-present\n",
    "    temp_alpha=0\n",
    "    data=ds_anoms_rolling.isel(time=slice(6, -6))\n",
    "    for Y in tqdm(range(0,-(time_fristpart+time_secondpart),-1)):\n",
    "        lv.reset()\n",
    "        if abs(Y)<time_fristpart:\n",
    "            lv.rotate('y', Y)\n",
    "            lv.render()\n",
    "            # Y-=1\n",
    "        elif abs(Y)>time_fristpart and abs(Y)<time_fristpart+time_secondpart:\n",
    "            time_index=abs(Y)-time_fristpart\n",
    "            # for time in tqdm(data.time.values[6:300]): \n",
    "            # if temp_alpha<ALPHA:\n",
    "            #     temp_alpha+=ALPHA/(ALPHA_TIME*fps)\n",
    "            if time_fristpart+time_secondpart-abs(Y) < ALPHA_TIME*fps and temp_alpha>0:\n",
    "                # print(Y)\n",
    "                temp_alpha-=ALPHA/(ALPHA_TIME*fps)\n",
    "                # print(temp_alpha)\n",
    "            elif abs(Y)-time_fristpart<ALPHA_TIME*fps and temp_alpha<ALPHA:\n",
    "                temp_alpha+=ALPHA/(ALPHA_TIME*fps)\n",
    "                \n",
    "            rgba_obs_anoms=generate_rgba(data.tos.isel(time=time_index),data['lon'], data['lat'], vmax=1, vmin=-1, Alpha=temp_alpha)\n",
    "            smoothed = gaussian_filter(rgba_obs_anoms, sigma=0.5)\n",
    "            accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "            lv.rotate('y', Y)\n",
    "            lv.title(\"NOAA-ERSSTv5 SSTA\")\n",
    "            lv.render()\n",
    "\n",
    "    lv.title(\"\")\n",
    "    # Zoom in to Australia\n",
    "    lv.flyto(cam_aust,steps=150)\n",
    "\n",
    "    # SSTA in Australian region\n",
    "    for Y in tqdm(range(0,-time_thirdpart,-1)):\n",
    "        time_index=abs(Y)\n",
    "        \n",
    "        if time_thirdpart-abs(Y) < ALPHA_TIME*fps and temp_alpha>0:\n",
    "            # print(Y)\n",
    "            temp_alpha-=ALPHA/(ALPHA_TIME*fps)\n",
    "            # print(temp_alpha)\n",
    "        elif abs(Y)-time_thirdpart<ALPHA_TIME*fps and temp_alpha<ALPHA:\n",
    "            temp_alpha+=ALPHA/(ALPHA_TIME*fps)\n",
    "\n",
    "        lon = data['lon']\n",
    "        lat = data['lat']\n",
    "        rgba_obs_anoms=generate_rgba(data.tos.isel(time=time_index), lon, lat, vmax=1, vmin=-1, Alpha=temp_alpha)\n",
    "        smoothed = gaussian_filter(rgba_obs_anoms, sigma=0.5)\n",
    "        accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "        lv.render()\n",
    "\n",
    "    # Zoom out to the western Pacific tropical region.\n",
    "    lv.flyto(cam_westpacific,steps=100)\n",
    "\n",
    "    # Pause at the end for 2 seconds\n",
    "    for i in range(2*fps):\n",
    "        lv.render()\n",
    "\n",
    "    # show 31 years trends from 1850 to 1980, rotate gradually to the east\n",
    "    temp_alpha=0\n",
    "    test_data_range=len(data_interp.year)\n",
    "    pos0=lv.camera()\n",
    "    pos1=cam_eastpacific\n",
    "    lv.title(\"Pacific SST Trend 31 years\")\n",
    "    for year in tqdm(range(test_data_range)):\n",
    "        if year < ALPHA_TIME * fps and temp_alpha<ALPHA:\n",
    "            temp_alpha+=ALPHA/(ALPHA_TIME*fps)\n",
    "        # elif year>test_data_range-(ALPHA_TIME * fps) and temp_alpha>0:\n",
    "        #     temp_alpha-=ALPHA/(ALPHA_TIME*fps)\n",
    "        data = data_interp.isel(year=year)\n",
    "        rgba=generate_rgba(data, data['lon'], data['lat'], Alpha=temp_alpha)\n",
    "        smoothed = gaussian_filter(rgba, sigma=0.5)\n",
    "        accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "        L = year / (test_data_range - 1)\n",
    "        lv.camlerp(pos0, pos1, L)\n",
    "        \n",
    "        lv.render()\n",
    "\n",
    "    # Pause for 5 seconds\n",
    "    for i in range(5*fps):\n",
    "        lv.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf244dc-b568-4c7e-b93a-3ce10b9a4a3a",
   "metadata": {},
   "source": [
    "# Generate Trend Video for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7639fbfa-df60-4324-8b3c-4b5b8aebeae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_obs_interp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_list\u001b[38;5;241m=\u001b[39m[\u001b[43mds_obs_interp\u001b[49m,ds_model_interp]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_obs_interp' is not defined"
     ]
    }
   ],
   "source": [
    "model_list=[ds_interp_obs,ds_interp_mdoel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17968748-7740-4e06-80eb-0ded2fe21707",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Sending large graph of size\",\n",
    "    category=UserWarning,\n",
    "    module=\"distributed.client\"\n",
    ")\n",
    "\n",
    "path=\"Path to store the video\"# Path to store the video\n",
    "\n",
    "for i, data in enumerate(model_list)\n",
    "    lv = accessvis.plot_earth(texture='bluemarble', background=\"white\", vertical_exaggeration=20)\n",
    "    data_interp=data\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        message=\"Sending large graph of size\",\n",
    "        category=UserWarning,\n",
    "        module=\"distributed.client\"\n",
    "    )\n",
    "    \n",
    "    with lv.video(filename=os.path.join(path,f\"Trend_{i}.mp4\"), quality=2, resolution=(600,600), width=600, height=600, fps=30) as v:\n",
    "        ALPHA=0.65\n",
    "        ALPHA_TIME=1.5\n",
    "        \n",
    "        fps=v.framerate\n",
    "        lv.camera(cam_eastpacific)\n",
    "        lv.title(\"NOAA-ERSSTv5\")\n",
    "    \n",
    "        temp_alpha=ALPHA\n",
    "        data=data_interp.isel(year=-1)\n",
    "        rgba_east=generate_rgba(data, data['lon'], data['lat'], Alpha=temp_alpha)\n",
    "        smoothed = gaussian_filter(rgba_east, sigma=0.5)\n",
    "        accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "        for i in tqdm(range(6*fps)):\n",
    "            if 6*fps-i<ALPHA_TIME*fps:\n",
    "                temp_alpha-=ALPHA/(ALPHA_TIME*fps)\n",
    "                rgba_east=generate_rgba(data, data['lon'], data['lat'], Alpha=temp_alpha)\n",
    "                smoothed = gaussian_filter(rgba_east, sigma=0.5)\n",
    "                accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "            \n",
    "            lv.render()\n",
    "    \n",
    "        lv.flyto(cam_westpacific,steps=3*fps)\n",
    "    \n",
    "        temp_alpha=0\n",
    "        test_data_range=len(data_interp.year)\n",
    "        pos0=lv.camera()\n",
    "        pos1=cam_eastpacific\n",
    "        for year in tqdm(range(test_data_range)):\n",
    "            if year < ALPHA_TIME * fps and temp_alpha<ALPHA:\n",
    "                temp_alpha+=ALPHA/(ALPHA_TIME*fps)\n",
    "            data = data_interp.isel(year=year)\n",
    "            rgba=generate_rgba(data, data['lon'], data['lat'], Alpha=temp_alpha)\n",
    "            smoothed = gaussian_filter(rgba, sigma=0.5)\n",
    "            accessvis.update_earth_values(lv, dataMode=0, data=smoothed)\n",
    "            L = year / (test_data_range - 1)\n",
    "            lv.camlerp(pos0, pos1, L)\n",
    "    \n",
    "            lv.render()\n",
    "    \n",
    "        for i in tqdm(range(3*fps)):\n",
    "            lv.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b4ae4-a8b2-4ae3-98f5-efb2cbba7497",
   "metadata": {},
   "source": [
    "# Concatenate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86e399-2823-4ba5-81ed-11a2e0b10bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import VideoFileClip, clips_array\n",
    "import cv2\n",
    "\n",
    "video1 = os.path.join(path, \"Trend_1.mp4\")\n",
    "video2 = os.path.join(path, \"Trend_2.mp4\")\n",
    "\n",
    "# Open videos\n",
    "cap1 = cv2.VideoCapture(video1)\n",
    "cap2 = cv2.VideoCapture(video2)\n",
    "\n",
    "# Get video parameters (using first video as reference)\n",
    "fps = int(cap1.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Output video settings: width × 2 for horizontal concatenation\n",
    "out = cv2.VideoWriter(\n",
    "    os.path.join(path, \"merged_side_by_side.mp4\"),\n",
    "    cv2.VideoWriter_fourcc(*'avc1'),\n",
    "    fps,\n",
    "    (width * 2, height)\n",
    ")\n",
    "\n",
    "# Get frame count from the shorter video\n",
    "frame_count = int(min(cap1.get(cv2.CAP_PROP_FRAME_COUNT),\n",
    "                      cap2.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "for i in range(frame_count):\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    if not (ret1 and ret2):\n",
    "        break\n",
    "    \n",
    "    # Resize to match dimensions (prevent resolution mismatch)\n",
    "    frame2 = cv2.resize(frame2, (width, height))\n",
    "    \n",
    "    # Horizontal concatenation\n",
    "    combined = np.hstack((frame1, frame2))\n",
    "    out.write(combined)\n",
    "\n",
    "# Release resources\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()RetryClaude can make mistakes. Please double-check responses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-25.09] *",
   "language": "python",
   "name": "conda-env-analysis3-25.09-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
